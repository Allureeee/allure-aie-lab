# HW07 – Report

> Файл: `homeworks/HW07/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Datasets

- `S07-hw-dataset-01.csv`  
- `S07-hw-dataset-02.csv`  
- `S07-hw-dataset-03.csv`  

### 1.1 Dataset A

- Файл: `S07-hw-dataset-01.csv`
- Размер: (12000, 9) (включая sample_id; признаков 8)
- Признаки: только числовые (f01…f08), sample_id — идентификатор (не признак)
- Пропуски: нет (NaN = 0 по всем колонкам)
- "Подлости" датасета: признаки в разных шкалах + присутствуют шумовые/слабополезные признаки → без масштабирования distance-based методы сильно искажают разбиение

### 1.2 Dataset B

- Файл: `S07-hw-dataset-02.csv`
- Размер: (8000, 4) (включая sample_id; признаков 3: x1, x2, z_noise)
- Признаки: только числовые, sample_id — идентификатор (не признак)
- Пропуски: нет
- "Подлости" датасета: нелинейная структура + выбросы/шум; лишний шумовой признак z_noise (может мешать расстояниям)

### 1.3 Dataset C

- Файл: `S07-hw-dataset-03.csv`  
- Размер: (15000, 5) (включая sample_id; признаков 4: x1, x2, f_corr, f_noise)
- Признаки: только числовые, sample_id — идентификатор (не признак)
- Пропуски: нет
- "Подлости" датасета: кластеры разной плотности + фон/шум → DBSCAN чувствителен к выбору eps (единый eps плохо подходит всем плотностям)

## 2. Protocol

- Препроцессинг: 
  - для каждого датасета формировала X как все колонки кроме sample_id;
  - применяла StandardScaler к числовым признакам через ColumnTransformer (без категориальных признаков и без imputation, т.к. пропусков нет);
  - одинаковый препроцессинг использовался для всех моделей внутри одного датасета (общий X_scaled).

- Поиск гиперпараметров:
  - KMeans: перебор k в диапазоне 2…20, фиксировала random_state=42 и n_init=10; DBSCAN: grid-search по eps (набор значений) и min_samples (набор значений);
  - “лучшее” выбирала по максимуму silhouette (для DBSCAN — на non-noise точках), при равенстве предпочитала меньшую долю шума.

- Метрики: считала silhouette_score, davies_bouldin_score, calinski_harabasz_score.
  - Для DBSCAN отдельно выводила долю шума (label=-1) и считала метрики только на non-noise точках (labels != -1), т.к. иначе метрики трудно интерпретировать.
  - Для ускорения silhouette на больших выборках использовала подвыборку (sample_size) (при этом это всё ещё silhouette_score).

- Визуализация: 
  - для каждого датасета строила PCA(2D) scatter для лучшего решения;
  - дополнительно сохраняла графики “silhouette vs k” (подбор KMeans), а также анализировала подбор DBSCAN через таблицу/grid метрик.
  - t-SNE не использовала (опционально).
## 3. Models

Перечислите, какие модели сравнивали **на каждом датасете**, и какие параметры подбирали.

- KMeans: подбирала k в диапазоне 2…20, фиксировала random_state=42, n_init=10
- DBSCAN: подбирала eps и min_samples, выводила долю шума (noise_share), метрики считала на non-noise точках

## 4. Results

Для каждого датасета – краткая сводка результатов.

### 4.1 Dataset A

- Лучший метод и параметры: KMeans, k=2
- Метрики: KMeans: 0.5185 / 0.6853 / 11786.95
- DBSCAN (лучшее по сетке): noise_share = 0.0735, silhouette = 0.3956 (метрики на non-noise), качество ниже KMeans
- Коротко: структура близка к хорошо разделимым шаровым группам, и KMeans после StandardScaler даёт высокий silhouette и лучшие внутренние метрики.

### 4.2 Dataset B

- Лучший метод и параметры: DBSCAN, eps=0.6, min_samples=12
- Метрики: 
  - KMeans (лучший k=2): 0.3058 / 1.3235 / 3573.39
  - DBSCAN (non-noise): 0.3102 / 0.6919 / 36.49
- DBSCAN: noise_share = 0.0589, метрики считались на non-noise; метод удобен тем, что отделяет выбросы/шум
- Коротко: датасет содержит выбросы/шум и хуже соответствует “шарам”; DBSCAN естественно выделяет плотное ядро и маркирует шум как -1, поэтому выбран как более уместный по смыслу структуры, даже при близких значениях silhouette.

### 4.3 Dataset C

- Лучший метод и параметры: KMeans, k=4
- Метрики: 
  - KMeans: 0.3141 / 1.1597 / 6492.28
  - DBSCAN (non-noise): 0.2163 / 0.9535 / 686.97
- DBSCAN: noise_share = 0.6351 (очень высокая доля шума), из-за чего значительная часть данных исключается из кластеров; метрики считались на non-noise
- Коротко: из-за разной плотности кластеров DBSCAN трудно подобрать одним eps: он “теряет” много точек в шум; KMeans с фиксированным k даёт более стабильное и интерпретируемое разбиение.

## 5. Analysis

### 5.1 Сравнение алгоритмов (важные наблюдения)

- KMeans ломается, когда структура не близка к шарам, есть сильные выбросы или неоднородная плотность: он всё равно разрезает пространство на области вокруг центров и может притягивать выбросы к кластерам. Это особенно заметно на dataset-02 (выбросы/шум) и частично на dataset-03 (сложная плотностная структура).

- DBSCAN выигрывает, когда важны выбросы и плотностная логика: он умеет помечать шум (-1) и выделять плотные области без задания k (dataset-02).

- DBSCAN проигрывает на данных с разной плотностью: единый eps плохо подходит всем кластерам, из-за чего либо растёт шум, либо сливаются кластеры (dataset-03: noise_share ~ 0.635).

- Самый сильный фактор качества для всех distance-based методов — масштабирование: без StandardScaler результат становится некорректным (особенно на dataset-01 с разными шкалами).

- Для интерпретации метрик при DBSCAN критично явно фиксировать, как учитывается шум: в работе метрики считались на non-noise, и отдельно выводилась доля шума.

### 5.2 Устойчивость (обязательно для одного датасета)

- Проверка: выбрала dataset-01 и сделала 5 запусков KMeans с разными random_state, затем посчитала попарный ARI между разбиениями.
- Результат: во всех попарных сравнениях ARI = 1.0, то есть все разбиения полностью совпали.
- Вывод: KMeans на dataset-01 полностью устойчив к инициализации (для выбранного k=2), что дополнительно подтверждает корректность выбора метода для этого датасета.

### 5.3 Интерпретация кластеров

- Интерпретацию делала через анализ профилей признаков: для каждого кластера можно смотреть средние/медианы по признакам (и отдельно шум -1 для DBSCAN).
- На dataset-01 кластеры хорошо отделяются и ожидаемо отличаются по нескольким признакам одновременно (после масштабирования видно стабильное разбиение).
- На dataset-02 DBSCAN выделяет плотную группу и шум: интерпретация здесь сводится к ядро распределения vs выбросы/фон.
- На dataset-03 часть точек по плотностному критерию уходит в шум при DBSCAN, поэтому интерпретация DBSCAN кластеров становится менее репрезентативной для полного датасета; KMeans даёт более полное покрытие точек.

## 6. Conclusion

- Масштабирование (StandardScaler) — обязательный шаг для корректной кластеризации distance-based методами.
- KMeans хорошо работает на данных, близких к компактным “шаровым” кластерам, но чувствителен к выбросам и неестественным формам.
- DBSCAN полезен, когда важны выбросы/шум и плотностная структура, и когда не хочется задавать k заранее.
- Для DBSCAN нужно явно учитывать шум (-1) и честно описывать, как считались метрики (я считала на non-noise и отдельно фиксировала долю шума).
- Внутренние метрики (silhouette/DB/CH) помогают сравнивать решения без истинных меток, но выбор “лучшего” должен учитывать и интерпретируемость структуры.
- Проверка устойчивости (через ARI между разными seed) помогает убедиться, что результат не является артефактом случайной инициализации.
