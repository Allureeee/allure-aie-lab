{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84d5f602",
   "metadata": {},
   "source": [
    "# HW05 — Бейзлайн vs Logistic Regression (Pipeline)\n",
    "\n",
    "**Цель:** сравнить простой бейзлайн (`DummyClassifier`) и логистическую регрессию (`LogisticRegression`) на датасете дефолтов.\n",
    "\n",
    "> Важно: ноутбук предполагается запускать из папки `homeworks/HW05/`, поэтому пути к файлам — **относительные**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88264f72",
   "metadata": {},
   "source": [
    "## 2.3.1 Импорты, загрузка датасета и первичный анализ (EDA-lite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6138e2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Базовые библиотеки (как в demo)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Воспроизводимость\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# sklearn: разбиение и модели\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# метрики\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, roc_auc_score,\n",
    "    precision_score, recall_score, f1_score,\n",
    "    roc_curve, precision_recall_curve, average_precision_score\n",
    ")\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87700e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка датасета\n",
    "df = pd.read_csv(\"S05-hw-dataset.csv\")\n",
    "print(\"Shape:\", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312f3c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Информация о столбцах и типах\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7fb12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Описательные статистики\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577951a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Распределение таргета\n",
    "print(df[\"default\"].value_counts())\n",
    "print()\n",
    "print(df[\"default\"].value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7209e5c",
   "metadata": {},
   "source": [
    "**Короткие наблюдения:**\n",
    "\n",
    "- В датасете 3000 объектов и 17 столбцов (из них default — таргет, client_id — технический идентификатор; для модели его обычно исключают).\n",
    "\n",
    "- Пропусков не обнаружено (можно подтвердить df.isna().sum()), типы — в основном целочисленные, несколько вещественных.\n",
    "\n",
    "- По диапазонам признаков (возраст, доход, кредитный скор, debt_to_income, бинарные флаги) явных выбросов по условиям из описания нет.\n",
    "\n",
    "- Есть аномалия по смыслу: у части клиентов years_employed > age (276 строк, ~9.2%), что невозможно, если years_employed — “стаж работы в годах”. Это стоит отметить как качество данных/синтетическую особенность.\n",
    "\n",
    "- Таргет умеренно несбалансирован: default=0 — 1769 (≈58.97%), default=1 — 1231 (≈41.03%).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc973768",
   "metadata": {},
   "source": [
    "## 2.3.2 Подготовка признаков и таргета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96f6163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X — все признаки кроме default и client_id, y — таргет default\n",
    "y = df[\"default\"].astype(int)\n",
    "X = df.drop(columns=[\"default\", \"client_id\"])\n",
    "\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)\n",
    "print(\"All numeric:\", X.select_dtypes(exclude=[np.number]).shape[1] == 0)\n",
    "\n",
    "# простая проверка диапазонов (по желанию)\n",
    "print(\"debt_to_income out of [0,1]:\", ((X[\"debt_to_income\"] < 0) | (X[\"debt_to_income\"] > 1)).sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e575a8e",
   "metadata": {},
   "source": [
    "## 2.3.3 Train/Test-сплит и бейзлайн-модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a8bcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Test split (как в demo: фиксируем random_state и используем stratify)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(\"Train:\", X_train.shape, \"Test:\", X_test.shape)\n",
    "print(\"Target share train:\", y_train.value_counts(normalize=True).round(4).to_dict())\n",
    "print(\"Target share test :\", y_test.value_counts(normalize=True).round(4).to_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d328cdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Бейзлайн: DummyClassifier (most_frequent)\n",
    "baseline = DummyClassifier(strategy=\"most_frequent\", random_state=RANDOM_STATE)\n",
    "baseline.fit(X_train, y_train)\n",
    "\n",
    "y_pred_dummy = baseline.predict(X_test)\n",
    "y_proba_dummy = baseline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "base_acc = accuracy_score(y_test, y_pred_dummy)\n",
    "base_auc = roc_auc_score(y_test, y_proba_dummy)\n",
    "\n",
    "print(\"=== DummyClassifier (most_frequent) – test ===\")\n",
    "print(\"Accuracy:\", base_acc)\n",
    "print(\"ROC-AUC :\", base_auc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b4458c",
   "metadata": {},
   "source": [
    "**Объяснение:**\n",
    "\n",
    "- most_frequent всегда предсказывает самый частый класс (здесь это default=0), поэтому accuracy примерно равен доле нулевого класса, а ROC-AUC ≈ 0.5 (модель не различает классы).\n",
    "\n",
    "- stratified предсказывает классы случайно, сохраняя пропорции классов из train, поэтому и accuracy, и ROC-AUC близки к случайному угадыванию.\n",
    "\n",
    "- Бейзлайн важен как точка отсчёта: любая нормальная модель должна уверенно превосходить эти значения, иначе она не приносит пользы."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7482837",
   "metadata": {},
   "source": [
    "## 2.3.4 Логистическая регрессия (Pipeline) и подбор гиперпараметра `C`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf7f6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline: StandardScaler + LogisticRegression\n",
    "pipe = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"logreg\", LogisticRegression(max_iter=2000, solver=\"lbfgs\"))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff3fbe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подбор C простым перебором — быстро и воспроизводимо\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(\n",
    "    X_train, y_train,\n",
    "    test_size=0.2,\n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=y_train\n",
    ")\n",
    "\n",
    "C_list = [0.01, 0.1, 1.0, 10.0]\n",
    "best_auc_val, best_C = -1.0, None\n",
    "\n",
    "for C in C_list:\n",
    "    pipe.set_params(logreg__C=C)\n",
    "    pipe.fit(X_tr, y_tr)\n",
    "    y_val_proba = pipe.predict_proba(X_val)[:, 1]\n",
    "    auc_val = roc_auc_score(y_val, y_val_proba)\n",
    "    print(f\"C={C:<5} | val ROC-AUC={auc_val:.4f}\")\n",
    "    if auc_val > best_auc_val:\n",
    "        best_auc_val, best_C = auc_val, C\n",
    "\n",
    "print(\"\\nBest C:\", best_C, \"| Best val ROC-AUC:\", round(best_auc_val, 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a80a809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучаем лучшую модель на полном train и оцениваем на test\n",
    "pipe.set_params(logreg__C=best_C)\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "y_pred_lr = pipe.predict(X_test)\n",
    "y_proba_lr = pipe.predict_proba(X_test)[:, 1]\n",
    "\n",
    "lr_acc = accuracy_score(y_test, y_pred_lr)\n",
    "lr_auc = roc_auc_score(y_test, y_proba_lr)\n",
    "\n",
    "print(\"=== LogisticRegression (best C) – test ===\")\n",
    "print(\"Accuracy:\", lr_acc)\n",
    "print(\"ROC-AUC :\", lr_auc)\n",
    "\n",
    "# дополнительные метрики (опционально, но полезно)\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_lr))\n",
    "print(\"Recall   :\", recall_score(y_test, y_pred_lr))\n",
    "print(\"F1-score :\", f1_score(y_test, y_pred_lr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5beb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC curve + сохранение в figures/\n",
    "fpr, tpr, _ = roc_curve(y_test, y_proba_lr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label=f\"LogReg (AUC={lr_auc:.3f})\")\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\", label=\"Random\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC curve (TEST)\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.savefig(\"figures/roc_curve.png\", dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6212ae2",
   "metadata": {},
   "source": [
    "## 2.3.5 Сравнение моделей и выводы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b67790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Табличка сравнения (Dummy vs LogReg)\n",
    "summary = pd.DataFrame([\n",
    "    {\"model\": \"Dummy (most_frequent)\", \"accuracy\": base_acc, \"roc_auc\": base_auc},\n",
    "    {\"model\": f\"LogReg (best C={best_C})\", \"accuracy\": lr_acc, \"roc_auc\": lr_auc},\n",
    "])\n",
    "\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e390c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Насколько выросли метрики (LogReg - Dummy)\n",
    "delta = summary.loc[1, [\"accuracy\", \"roc_auc\"]] - summary.loc[0, [\"accuracy\", \"roc_auc\"]]\n",
    "print(\"Δaccuracy:\", float(delta[\"accuracy\"]))\n",
    "print(\"ΔROC-AUC :\", float(delta[\"roc_auc\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce7c46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = f\"\"\"В качестве точки отсчёта использовалась бейзлайн-модель DummyClassifier (most_frequent), которая всегда предсказывает самый частый класс.\n",
    "Её качество на тестовой выборке: accuracy = {base_acc:.3f}, ROC-AUC = {base_auc:.3f}.\n",
    "Логистическая регрессия (Pipeline: StandardScaler + LogisticRegression) показала заметно лучшее качество: accuracy = {lr_acc:.3f}, ROC-AUC = {lr_auc:.3f}.\n",
    "Прирост по сравнению с бейзлайном составил: Δaccuracy = {lr_acc - base_acc:+.3f}, ΔROC-AUC = {lr_auc - base_auc:+.3f}.\n",
    "При переборе нескольких значений C качество по ROC-AUC менялось незначительно (на валидации), поэтому модель стабильна к разумным изменениям силы регуляризации.\n",
    "Лучшая настройка на нашей проверке: C = {best_C}.\n",
    "В целом логистическая регрессия выглядит разумной для этой задачи: она проста, интерпретируема и существенно превосходит бейзлайн по ROC-AUC.\n",
    "\"\"\"\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8b1443",
   "metadata": {},
   "source": [
    "## 2.4 Опционально: PR-кривая и метрики при пороге"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca80afd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PR curve + Average Precision (AP) + сохранение\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_proba_lr)\n",
    "ap = average_precision_score(y_test, y_proba_lr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(recall, precision, label=f\"LogReg (AP={ap:.3f})\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision-Recall curve (TEST)\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.savefig(\"figures/pr_curve.png\", dpi=500)\n",
    "plt.show()\n",
    "\n",
    "print(\"Average Precision:\", ap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa94a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# precision/recall/f1 для выбранного порога (например, 0.5)\n",
    "threshold = 0.5\n",
    "y_pred_thr = (y_proba_lr >= threshold).astype(int)\n",
    "\n",
    "print(\"Threshold:\", threshold)\n",
    "print(\"precision:\", precision_score(y_test, y_pred_thr))\n",
    "print(\"recall   :\", recall_score(y_test, y_pred_thr))\n",
    "print(\"f1       :\", f1_score(y_test, y_pred_thr))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
