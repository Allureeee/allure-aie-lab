# HW06 – Report

> Файл: `homeworks/HW06/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Dataset

- Какой датасет выбран: `S06-hw-dataset-02.csv`
- Размер: (18000, 39)
- Целевая переменная: `target` (классы и их доли):
    - 0: 13273 (0.7374)
    - 1: 4727 (0.2626)
- Признаки: что за типы (числовые / категориальные-подобные, если есть):
    - 37 признаков типа float64
    - id и target — int64
    - id исключён из признаков (не используем как feature)

## 2. Protocol

- Разбиение: train/test (доли, `random_state`)
    - test_size = 0.2
    - random_state = 42
    - stratify = y (сохраняем доли классов в train/test)
- Подбор: CV на train (сколько фолдов, что оптимизировали)
    - StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
    - оптимизировали ROC-AUC (подбор гиперпараметров через GridSearchCV только на train)
- Метрики: accuracy, F1, ROC-AUC (и почему эти метрики уместны именно здесь)
    - accuracy — базовая метрика, показывает долю верных ответов
    - F1 — важна при дисбалансе классов (учитывает precision/recall)
    - ROC-AUC — особенно уместна для бинарной классификации с вероятностями: оценивает качество ранжирования и не зависит от фиксированного порога 0.5

## 3. Models

- **DummyClassifier** (baseline)
    - strategy="most_frequent" (без подбора)

- **LogisticRegression**
    - Pipeline(StandardScaler + LogisticRegression)
    - GridSearch по C (например [0.1, 1.0, 10.0]), solver="lbfgs"

- **DecisionTreeClassifier** (контроль сложности: max_depth + min_samples_leaf или ccp_alpha)
GridSearch по:
    - max_depth: [None, 3, 5, 8]
    - min_samples_leaf: [1, 5, 10, 20]
    - ccp_alpha: [0.0, 0.001, 0.005, 0.01]

- **RandomForestClassifier**   
GridSearch по:
    - max_depth: [None, 6, 10]
    - min_samples_leaf: [1, 5, 10]
    - max_features: ["sqrt", 0.5]

- **HistGradientBoosting** (быстрый бустинг для табличных данных)    
GridSearch по:
    - learning_rate: [0.03, 0.05, 0.1]
    - max_depth: [2, 3, None]
    - max_leaf_nodes: [15, 31, 63]

- **StackingClassifier** (с CV-логикой)
    - Базовые модели: LogReg(scaled), RandomForest, HistGradientBoosting
    - Мета-модель: LogisticRegression
    - Внутри StackingClassifier используется CV (чтобы метамодель училась без утечки)

## 4. Results
    
- Метрики собраны в файле артефактов: artifacts/metrics_test.csv   
Кратко (заполнить из своей таблицы результатов):
    - Dummy: accuracy= 0.7375, f1=0.0000, roc_auc=0.5000
    - LogReg(scaled): accuracy=0.8119, f1=0.5607, roc_auc=0.7977
    - DecisionTree: accuracy=0.8264, f1=0.6549, roc_auc=0.8326
    - RandomForest: accuracy=0.8922, f1=0.7611, roc_auc=0.9289
    - HistGradientBoosting: accuracy=0.9053, f1=0.8025, roc_auc=0.9312
    - (Stacking): accuracy=0.9133, f1=0.8249, roc_auc=0.9340

- Победитель по выбранному критерию (**ROC-AUC**) — **Stacking**:
    - accuracy = **0.9133**
    - f1 = **0.8249**
    - roc_auc = **0.9340**

Стэкинг показал лучшее качество ранжирования (ROC-AUC) и одновременно лучшие значения accuracy и f1 на test.

## 5. Analysis
- Устойчивость:   
    - При фиксированном train/test разбиении результаты воспроизводимы (random_state=42). 

    - Дополнительно можно проверить устойчивость на нескольких seed (1–2 модели, 5 прогонов), но в рамках этой работы основная цель — честное сравнение моделей при одном фиксированном разбиении. 

- Ошибки:
    - Confusion matrix для лучшей модели (Stacking) построена на test (см. `artifacts/figures/confusion_matrix.png`).
    - По матрице можно оценить, каких ошибок больше: FP (ложные срабатывания) или FN (пропуски класса 1).
    - При необходимости баланс ошибок можно менять, подбирая порог по вероятностям (не обязательно 0.5).
    - Confusion matrix (Stacking, test): TN=2553, FP=102, FN=210, TP=735.
    Модель хорошо распознаёт класс 0 (ошибок FP мало: 102), но пропусков положительного класса (FN=210) больше, чем ложных срабатываний.
То есть модель осторожнее ставит класс 1: чаще “не находит” часть объектов класса 1.
При необходимости можно уменьшить FN, сдвинув порог классификации (снизив threshold), но тогда вырастет FP.

- Интерпретация:
  Permutation importance (top-15) рассчитан для лучшей модели (Stacking) на test (scoring = ROC-AUC).
  Самый важный признак — f16, далее f01, f07, f08, f30 и f19; остальные признаки дают меньший вклад.
  Так как признаки анонимизированы (fXX), смысловая интерпретация ограничена.
- Посчитан permutation importance для лучшей модели (top-15). Получилось:
    - f16: 0.045908
    - f01: 0.019233
    - f07: 0.014723
    - f08: 0.013061
    - f30: 0.012529
    - f19: 0.012355
    - f12: 0.009649
    - f05: 0.008889
    - f15: 0.007871
    - f13: 0.007869
    - f29: 0.007440
    - f02: 0.007332
    - f23: 0.007216
    - f18: 0.007067
    - f34: 0.005531

Вывод: самый важный признак — f16 (при его перемешивании качество падает сильнее всего), далее идут f01, f07, f08, f30, f19. Остальные признаки из top-15 дают меньший вклад; часть важности может “размазываться” между коррелированными признаками. Так как признаки анонимизированы (fXX), интерпретация по смыслу ограничена: можно уверенно говорить о влиянии признаков на модель, но не о реальном содержании этих признаков.

## 6. Conclusion

- Лучший результат на test показал **Stacking**: accuracy = 0.9133, f1 = 0.8249, ROC-AUC = 0.9340.

- Ансамблевые методы (RandomForest, HistGradientBoosting, Stacking) существенно превосходят одиночное дерево и baseline логистическую регрессию, что ожидаемо для табличной бинарной задачи.

- Деревья решений без контроля сложности легко переобучаются, поэтому важно ограничивать глубину/листья или использовать ccp_alpha.

- Ансамбли (RandomForest, boosting) обычно дают качество выше одиночного дерева за счёт снижения дисперсии (RF) или последовательного исправления ошибок (boosting).

- ROC-AUC удобна как основная метрика для подбора в бинарной задаче с вероятностями, потому что не зависит от фиксированного порога.

- Честный протокол: подбор гиперпараметров делаем только на train через CV, а test используем для финальной оценки.

- Permutation importance помогает понять, какие признаки сильнее влияют на качество модели (в моём случае лидирует f16).
